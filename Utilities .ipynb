{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOOGLE TRENDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import csv\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open('multiTimeline.csv', newline='') as csvfile:\n",
    "    data = list(csv.reader(csvfile))\n",
    "google =data[3:]\n",
    "\n",
    "dates = []\n",
    "values = []\n",
    "for x in range(0, len(google)):\n",
    "    dates.append(str(google[x][0]))\n",
    "    values.append(google[x][1])\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "y_pos = np.arange(len(dates))\n",
    "\n",
    "\n",
    "plt.scatter(dates, values)\n",
    "\n",
    "plt.title('Google Trend Over time')\n",
    "plt.ylabel('Popularity as % of Max')\n",
    "plt.xticks(y_pos, dates, fontsize=10, rotation=30)\n",
    "plt.locator_params(axis='x', nbins=6)\n",
    "plt.locator_params(axis='Y', nbins=6)\n",
    "\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import csv\n",
    "import matplotlib.pyplot as plt; plt.rcdefaults()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open('geoMap.csv', newline='') as csvfile:\n",
    "    data = list(csv.reader(csvfile))\n",
    "google =data[3:]\n",
    "\n",
    "places = []\n",
    "values = []\n",
    "for x in range(0, len(google)):\n",
    "    places.append(str(google[x][0]))\n",
    "    values.append(google[x][1])\n",
    "    \n",
    "places = places[0:5]\n",
    "values = values[0:5]\n",
    "\n",
    "# this is for plotting purpose\n",
    "index = np.arange(len(places))\n",
    "plt.barh(index, values)\n",
    "plt.ylabel('District', fontsize=10)\n",
    "plt.xlabel('Proportion Index', fontsize=10)\n",
    "plt.yticks(index, places, fontsize=10, rotation=0)\n",
    "plt.title('Interest by subregion')\n",
    "plt.savefig(\"gcompare\")\n",
    "plt.show()\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCAN A TWEET FOR A GIVEN BIO¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "# selected in the beginning (at the top)\n",
    "CHOSEN_BIO_WORD = CHOSEN_BIO_WORD.upper()\n",
    "\n",
    "\n",
    "TARGETARRAY = []\n",
    "TARGETTWEET = \"\"\n",
    "linecount = 0\n",
    "for x in range(0, len(status_array)):\n",
    "    text = str(status_array[x]['text']).upper()\n",
    "    description = str(status_array[x]['user']['description']).upper()\n",
    "   \n",
    "    if str(description).count(str(CHOSEN_BIO_WORD)) >= 1:\n",
    "        TARGETARRAY.append(status_array[x])\n",
    "        TARGETTWEET = TARGETTWEET +  str(status_array[x]['text']).upper()\n",
    "\n",
    "\n",
    "\n",
    "DISC = TARGETTWEET.split()\n",
    "x = Counter(DISC)\n",
    "del x['⠀'],x['AND'],x['THE'],x['OF'],x['TO'],x['A'],x['IN'],x['&'],x['MY'],x['FOR'],x['I'],x['NOT'],x['IS'],x['ARE']\n",
    "del x['WITH'],x['ALL'],x['ON'],x['-'],x['YOU'],x['BY'],x['IT'],x['NO'],x['OR'],x['OWN'],x['THAT'],x['AT'],x['BE'],x['|'],x['WILL'],\n",
    "del x['BUT'],x['AN'],x['ABOUT'],x['AS'],x['FROM'],x['WHO'],x['ME'],x['WE'],x['HAVE'],x['OUR'],x['AM'],x['LIKE'],x['JUST']\n",
    "del x['THIS'],x['THEY'],x['IF'],x['HAS'],x['&AMP'],x['HAS'],x['CAN'],x['NOW'],x['SO'],x['ONLY'],x['WAS'],x['WHAT'],x['THEIR'],x['YOUR'],x['WOULD']\n",
    "del x['DO'],x['&AMP;'],x['ONE'],x['WANT'],x['BEEN'],x['THEM'],x['MORE'],x['/'],x['•'],x[\"I'M\"],x[''],x['']\n",
    "\n",
    "refinedTWEETS = OrderedDict(x.most_common(50))\n",
    "print(\"Number of matching tweets: \" + str(len(TARGETARRAY)))\n",
    "print(\"Top 50 terms in their tweets: \" + str(refinedTWEETS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCAN BIO FOR GIVEN TWEET¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "\n",
    "\n",
    "CHOSEN_TWEET_WORD = CHOSEN_TWEET_WORD.upper()\n",
    "\n",
    "\n",
    "TARGETARRAY = []\n",
    "TARGETBIO = \"\"\n",
    "linecount = 0\n",
    "for x in range(0, len(status_array)):\n",
    "    text = str(status_array[x]['text']).upper()\n",
    "    description = str(status_array[x]['user']['description']).upper()\n",
    "   \n",
    "    if str(text).count(str(CHOSEN_TWEET_WORD)) >= 1:\n",
    "        TARGETARRAY.append(status_array[x])\n",
    "        TARGETBIO = TARGETBIO + str(status_array[x]['user']['description']).upper()\n",
    "\n",
    "\n",
    "\n",
    "DISC = TARGETBIO.split()\n",
    "x = Counter(DISC)\n",
    "del x['⠀'],x['AND'],x['THE'],x['OF'],x['TO'],x['A'],x['IN'],x['&'],x['MY'],x['FOR'],x['I'],x['NOT'],x['IS'],x['ARE']\n",
    "del x['WITH'],x['ALL'],x['ON'],x['-'],x['YOU'],x['BY'],x['IT'],x['NO'],x['OR'],x['OWN'],x['THAT'],x['AT'],x['BE'],x['|'],x['WILL'],\n",
    "del x['BUT'],x['AN'],x['ABOUT'],x['AS'],x['FROM'],x['WHO'],x['ME'],x['WE'],x['HAVE'],x['OUR'],x['AM'],x['LIKE'],x['JUST']\n",
    "del x['THIS'],x['THEY'],x['IF'],x['HAS'],x['&AMP'],x['HAS'],x['CAN'],x['NOW'],x['SO'],x['ONLY'],x['WAS'],x['WHAT'],x['THEIR'],x['YOUR'],x['WOULD']\n",
    "del x['DO'],x['&AMP;'],x['ONE'],x['WANT'],x['BEEN'],x['THEM'],x['MORE'],x['/'],x['•'],x[\"I'M\"],x[''],x['']\n",
    "\n",
    "refinedBio = OrderedDict(x.most_common(50))\n",
    "print(\"Number of matching tweets: \" + str(len(TARGETARRAY)))\n",
    "print(\"Top 50 terms in their bio: \" + str(refinedBio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINK BIO AND TWEET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(large_top_tweets)\n",
    "print(\"\")\n",
    "print(\"bio\")\n",
    "print(large_bio_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PICK TWO OR \n",
    "\n",
    "CHOSEN_WORD_ONE = CHOSEN_TWEET_WORD_ONE.upper()\n",
    "BIO_CHOSEN_WORD_ONE = BIO_CHOSEN_WORD_ONE.upper()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "TARGETARRAY = []\n",
    "linecount = 0\n",
    "for x in range(0, len(status_array)):\n",
    "    text = str(status_array[x]['text']).upper()\n",
    "    description = str(status_array[x]['user']['description']).upper()\n",
    "   \n",
    "    if str(text).count(str(CHOSEN_WORD_ONE)) >= 1 and str(description).count(str(BIO_CHOSEN_WORD_ONE)) >= 1:\n",
    "        TARGETARRAY.append(status_array[x])\n",
    "\n",
    "\n",
    "match_percentage =  (len(TARGETARRAY)/len(status_array)) * 100\n",
    "match_percentage = round(match_percentage,2)\n",
    "print(\"No of matches : \" + str(match_percentage) + \"%\" )    \n",
    "print(TARGETARRAY[0]['text'])\n",
    "print(\"\")\n",
    "print('Bio: ')\n",
    "print(TARGETARRAY[0]['user']['description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_array[1]['user']['created_at']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
